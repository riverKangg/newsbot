import os
import sys
import time
import random
import json, re
from datetime import datetime
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from webdriver_manager.chrome import ChromeDriverManager
from bs4 import BeautifulSoup
from urllib.parse import quote

from summary.summarizer import NewsSummarizer
from crawl.naver_news_one import process_link
from api.kakao_notifier import KakaoNotifier

def generate_random_phone_number():
    middle = random.randint(1000, 9999)
    last = random.randint(1000, 9999)
    return f"010-{middle}-{last}"

def parse_response(response):
    try:
        # ì—¬ëŸ¬ ë²ˆ ë‚˜ëˆ„ì–´ì§„ ì‘ë‹µì„ í•˜ë‚˜ë¡œ í•©ì¹˜ê¸°
        if isinstance(response, list):
            response = "".join(response)
        
        # ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì œê±°
        response = response.strip()
        if '```json' in response:
            response = response.split('```json')[1]
        if '```' in response:
            response = response.split('```')[0]
        response = response.strip()
        
        # JSON ë¬¸ìì—´ ì •ê·œí™”
        response = response.replace('\n', ' ').replace('\r', '')
        response = re.sub(r'\s+', ' ', response)
        response = response.replace('False','false').replace('True','true')
        response = re.sub("'", '', response)

        # ì¤‘ë³µëœ JSON ì‘ë‹µ ì œê±°
        if response.count('{') > 1:
            # ë§ˆì§€ë§‰ ì™„ì „í•œ JSON ê°ì²´ë§Œ ì‚¬ìš©
            last_brace = response.rfind('}')
            if last_brace != -1:
                response = response[:last_brace+1]
        
        # JSON íŒŒì‹±
        result = json.loads(response)
        
        # í•„ìˆ˜ í•„ë“œê°€ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ê°’ ì„¤ì •
        if 'is_related' not in result:
            result['is_related'] = False
        if 'label' not in result:
            result['label'] = 'False'
        if 'summary' not in result:
            result['summary'] = 'ìš”ì•½ ì‹¤íŒ¨'
            
        # label ê°’ì´ ì˜ˆìƒëœ í˜•ì‹ì´ ì•„ë‹Œ ê²½ìš° ìˆ˜ì •
        if isinstance(result['label'], bool):
            result['label'] = 'True' if result['label'] else 'False'
        elif result['label'] not in ['True', 'False', 'Positive', 'Negative', 'Neutral']:
            result['label'] = 'False'
            
        return result
    except Exception as e:
        print(f"Unexpected error in parse_response: {e}")
        print(f"Raw response: {response}")
        return {
            'is_related': False,
            'label': 'Neutral',
            'summary': 'ìš”ì•½ ì‹¤íŒ¨'
        }

def process_content_with_prompt(content, prompt):
    try:
        summarizer = NewsSummarizer()
        sentdict_raw = summarizer.summarize_with_gpt(content, prompt)
        sentdict = parse_response(sentdict_raw)

        if sentdict is None:
            raise ValueError("Parsed dictionary is None.")

        is_related = sentdict.get('is_related', False)
        label = sentdict.get('label')
        summary = sentdict.get('summary')

        return is_related, label, summary
    except Exception as e:
        print(f"Error in process_content_with_prompt: {str(e)}")
        print(f"Content: {content[:100]}...")  # ì²« 100ìë§Œ ë¡œê¹…
        return False, "False", "ìš”ì•½ ì‹¤íŒ¨"

def web_driver():
    options = Options()
    options.add_argument('--headless')
    options.add_argument('--no-sandbox')
    options.add_argument('--disable-dev-shm-usage')
    options.add_argument('--disable-gpu')
    options.add_argument('--window-size=1920,1080')
    options.add_argument('--remote-debugging-port=9222')

    service = Service(ChromeDriverManager().install())
    driver = webdriver.Chrome(service=service, options=options)
    return driver

def build_naver_news_url(query, date):
    encoded_query = quote(query)
    option_date = f"ds={str(int(date[:4]))}.{date[4:6]}.{date[-2:]}&de={date[:4]}.{date[4:6]}.{date[-2:]}"
    url = f"https://search.naver.com/search.naver?where=news&query={encoded_query}&sm=tab_opt&sort=1&photo=0&field=0&pd=3&{option_date}"
    return url

def naver_news_scraper(query, date, category):
    print(f"ğŸ” ê²€ìƒ‰ ì‹œì‘ - ì¹´í…Œê³ ë¦¬: '{category}', í‚¤ì›Œë“œ: '{query}'")
    url = build_naver_news_url(query, date)
    driver = web_driver()
    results = [] 
    try:
        driver.get(url)
        time.sleep(1)
        soup = BeautifulSoup(driver.page_source, "html.parser")
        news_items = soup.select(".news_area")
        print(f"ğŸ“° ë°œê²¬ëœ ë‰´ìŠ¤ ìˆ˜: {len(news_items)}")
        for item in news_items:
            title_elem = item.select_one(".news_tit")
            title = title_elem.text.strip()
            link = title_elem["href"]
            press_elem = item.select_one(".info.press")
            press = press_elem.text.strip() if press_elem else "ì–¸ë¡ ì‚¬ ì •ë³´ ì—†ìŒ"
            desc_elem = item.select_one(".dsc_txt_wrap")
            description = desc_elem.text.strip() if desc_elem else "ìš”ì•½ ì •ë³´ ì—†ìŒ"

            test = item.find("div", class_="info_group")
            time_elem = test.find('span', class_='info').text.strip()
            naver_link = test.find_all('a')[-1].get('href') if test and 'naver' in test.find_all('a')[-1].get('href') else None

            # ì‹œê°„ íŒŒì‹± ë° í•„í„°ë§
            time_delta_minutes = None
            if 'ë¶„ ì „' in time_elem:
                time_delta_minutes = int(time_elem.replace('ë¶„ ì „', '').strip())
            elif 'ì‹œê°„ ì „' in time_elem:
                time_delta_minutes = int(time_elem.replace('ì‹œê°„ ì „', '').strip()) * 60
            with open("prompt/cnews_summary.txt", 'r',encoding='utf-8') as file:
                prompt = file.read()

            if naver_link is not None:
                print(f"ğŸ”— ê¸°ì‚¬ ë§í¬ ë¶„ì„ ì¤‘: {naver_link}")
                content, jour_link, jour_name = process_link(naver_link)
                summarizer = NewsSummarizer()
                is_related, label, summary = process_content_with_prompt(content, prompt)
 
                print(is_related, label)
                news_item = {
                    "category": category,
                    "keyword": query,
                    "title": title,
                    "press": press,
                    "description": description,
                    "url": link,
                    "naver_link": naver_link,
                    "time": time_elem,
                    "content": content,
                    "jour_name": jour_name,
                    "is_related": is_related,
                    "phone_number" : generate_random_phone_number(),
                    "label" : label,
                    "summary" : summary,
                }

                if label == "Negative" and time_delta_minutes is not None and time_delta_minutes <= 30:
                    notifier = KakaoNotifier()
                    notifier.notify(news_item)
                    results.append(news_item)
    finally:
        driver.quit()
    return results

if __name__ == "__main__":
    date = datetime.now().strftime('%Y%m%d')
    selected_keywords = {
        "test": ["ìœ¤ì„ì—´"],
        "ë‹¹ì‚¬": ["ì‚¼ì„±ìƒëª…", "í™ì›í•™"],
        "ë³´í—˜": ["ìƒëª…ë³´í—˜", "ì†í•´ë³´í—˜", "ìƒë³´", "ì†ë³´", "ë³´í—˜ì‚¬ê¸°",
                "ì‹¤ì†", "ë¬´í•´ì§€", "ì €í•´ì§€", "IFRS17", "í‚¥ìŠ¤",
                "ì‚¼ì„±í™”ì¬", "í•œí™”ìƒëª…", "êµë³´ìƒëª…", "ì‹ í•œë¼ì´í”„"],
        "ê·¸ë£¹": ["ì´ì¬ìš©", "í™ë¼í¬", "ì´ë¶€ì§„", "ì´ì„œí˜„", "ì‚¼ì„±ì „ì", "ì‚¼ì„±ë¬¼ì‚°"],
        "ê¸ˆìœµ": ["ê¸ˆìœµìœ„", "ê¸ˆê°ì›", "ê¹€ë³‘í™˜", "ì´ë³µí˜„", "ê¸ˆìœµì§€ì£¼"]
    }

    while True:
        for category, keyword_list in selected_keywords.items():
            for query in keyword_list:
                naver_news_scraper(query, date, category)

        print("[ëŒ€ê¸° ì¤‘ ğŸ’¤] 1ë¶„ í›„ ì¬ì‹œì‘\n")
        time.sleep(60)
