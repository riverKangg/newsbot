# news_kakao_sender.py
#!/usr/bin/env python3

import os
import requests
from bs4 import BeautifulSoup
from datetime import datetime
from dotenv import load_dotenv
import openai
import json
import time

load_dotenv()

KAKAO_TOKEN = os.getenv("ACCESS_TOKEN")
REST_API_KEY = os.getenv("REST_API_KEY")
REFRESH_TOKEN = os.getenv("REFRESH_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

KAKAO_URL = "https://kapi.kakao.com/v2/api/talk/memo/default/send"
NAVER_NEWS_URL = "https://news.naver.com/"

TARGET_KEYWORDS = ["ì‚¼ì„±ìƒëª…", "í™ì›í•™"]
HEADERS = {
    "Authorization": f"Bearer {KAKAO_TOKEN}",
    "Content-Type": "application/x-www-form-urlencoded"
}

openai.api_key = OPENAI_API_KEY


class TokenRefresher:
    def __init__(self, headers):
        self.headers = headers

    def refresh(self):
        token_url = "https://kauth.kakao.com/oauth/token"
        payload = {
            "grant_type": "refresh_token",
            "client_id": REST_API_KEY,
            "refresh_token": REFRESH_TOKEN,
        }

        response = requests.post(token_url, data=payload)
        if response.status_code == 200:
            new_token = response.json().get("access_token")
            if new_token:
                global KAKAO_TOKEN
                KAKAO_TOKEN = new_token
                self.headers["Authorization"] = f"Bearer {KAKAO_TOKEN}"
                print("ğŸ”‘ Access Token ê°±ì‹  ì™„ë£Œ")
            else:
                print("âš ï¸ Access Token ê°±ì‹  ì‹¤íŒ¨: ì‘ë‹µì— í† í° ì—†ìŒ")
        else:
            print("âŒ Access Token ê°±ì‹  ì‹¤íŒ¨", response.text)


class NewsCrawler:
    def __init__(self, news_url, categories):
        self.news_url = news_url
        self.categories = categories

    def crawl(self):
        response = requests.get(self.news_url)
        soup = BeautifulSoup(response.text, "html.parser")
        news_items = []

        for link in soup.select("a"):
            title = link.get_text(strip=True)
            href = link.get("href")
            if not title or not href:
                continue

            for category, keywords in self.categories.items():
                for keyword in keywords:
                    if keyword in title:
                        content = self.get_article_content(href)
                        summary = self.summarize_with_gpt(content)
                        news_items.append({
                            "title": title,
                            "url": href,
                            "keyword": keyword,
                            "category": category,
                            "summary": summary
                        })
                        break

        return news_items

    def get_article_content(self, url):
        try:
            response = requests.get(url, timeout=5)
            soup = BeautifulSoup(response.text, "html.parser")

            content_div = soup.find("div", {"id": "newsct_article"})
            if not content_div:
                paragraphs = soup.find_all("p")
                return " ".join(p.get_text() for p in paragraphs)

            text = content_div.get_text(separator=" ", strip=True)
            return text.strip()
        except Exception as e:
            return "ë³¸ë¬¸ ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤íŒ¨"

    def summarize_with_gpt(self, text):
        try:
            response = openai.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "You are a helpful assistant that summarizes news articles."},
                    {"role": "user", "content": f"ë‹¤ìŒ ê¸°ì‚¬ì˜ ë‚´ìš©ì„ í•œì¤„ë¡œ ìš”ì•½í•´ì¤˜: {text}"}
                ],
                max_tokens=150,
                n=1,
                stop=None,
                temperature=0.5,
            )
            summary = response.choices[0].message.content.strip()
            return summary
        except Exception as e:
            print("GPT ìš”ì•½ ì˜¤ë¥˜:", e)
            return "ìš”ì•½ ì‹¤íŒ¨"


class KakaoNotifier:
    def __init__(self, headers):
        self.headers = headers

    def notify(self, news_item):
        title = news_item['title']
        url = news_item['url']
        keyword = news_item['keyword']
        category = news_item['category']
        summary = news_item['summary']
        now = datetime.now().strftime("%Y.%m.%d %H:%M")

        message = f"\nğŸ“¢ ë¶„ë¥˜: \"{category}\"\ní‚¤ì›Œë“œ ê°ì§€ë¨: \"{keyword}\"\n\n"
        message += f"ğŸ“° {title}\nğŸ•“ {now}\nğŸ“ {url}\n\nğŸ“ ìš”ì•½: {summary}"

        data = {
            "template_object": {
                "object_type": "text",
                "text": message,
                "link": {
                    "web_url": url,
                    "mobile_web_url": url
                },
                "button_title": "ë‰´ìŠ¤ ë³´ê¸°"
            }
        }

        res = requests.post(KAKAO_URL, headers=self.headers, data={"template_object": json.dumps(data["template_object"])})
        if res.status_code == 200:
            print(f"âœ… ì „ì†¡ ì„±ê³µ: {title}")
        else:
            print(f"âŒ ì „ì†¡ ì‹¤íŒ¨! ìƒíƒœ ì½”ë“œ: {res.status_code}")
            print(res.text)


class NewsBot:
    def __init__(self):
        self.token_refresher = TokenRefresher(headers=HEADERS)

        # ì¹´í…Œê³ ë¦¬ë³„ í‚¤ì›Œë“œë¥¼ ì •ì˜í•©ë‹ˆë‹¤.
        self.categories = {
            "ë‹¹ì‚¬": ["ì‚¼ì„±ìƒëª…", "í™ì›í•™"],
            "ë³´í—˜": ["ìƒëª…ë³´í—˜", "ì†í•´ë³´í—˜", "ìƒë³´", "ì†ë³´", "ë³´í—˜ì‚¬ê¸°", "ì‹¤ì†", "ë¬´í•´ì§€", "ì €í•´ì§€", "IFRS17", "í‚¥ìŠ¤",
"ì‚¼ì„±í™”ì¬", "í•œí™”ìƒëª…", "êµë³´ìƒëª…", "ì‹ í•œë¼ì´í”„"],
            "ê·¸ë£¹": ["ì´ì¬ìš©", "í™ë¼í¬", "ì´ë¶€ì§„", "ì´ì„œí˜„", "ì‚¼ì„±ì „ì", "ì‚¼ì„±ë¬¼ì‚°"],
            "ê¸ˆìœµ": ["ê¸ˆìœµìœ„", "ê¸ˆê°ì›", "ê¹€ë³‘í™˜", "ì´ë³µí˜„", "ê¸ˆìœµì§€ì£¼"]
        }

        self.news_crawler = NewsCrawler(news_url=NAVER_NEWS_URL, categories=self.categories)
        self.notifier = KakaoNotifier(headers=HEADERS)
        self.sent_articles = self.load_sent_articles()

    def load_sent_articles(self, filepath="sent_articles.json"):
        try:
            with open(filepath, 'r') as file:
                return set(json.load(file))
        except (FileNotFoundError, json.JSONDecodeError):
            return set()

    def save_sent_articles(self, filepath="sent_articles.json"):
        with open(filepath, 'w') as file:
            json.dump(list(self.sent_articles), file)

    def run(self):
        print("[ë‰´ìŠ¤ë´‡ ì‹¤í–‰ ì¤‘ â°]", datetime.now())
        self.token_refresher.refresh()
        news = self.news_crawler.crawl()

        if not news:
            print("ğŸ“­ ì „ì†¡í•  ë‰´ìŠ¤ ì—†ìŒ")

        for item in news:
            if item['url'] not in self.sent_articles:
                self.notifier.notify(item)
                self.sent_articles.add(item['url'])
                print(f"ğŸ“¦ ê¸°ì‚¬ ì €ì¥: {item['title']}")
            else:
                print(f"ğŸ” ì¤‘ë³µ ê°ì§€, ê¸°ì‚¬ ìŠ¤í‚µ: {item['title']}")

        self.save_sent_articles()
if __name__ == "__main__":
    bot = NewsBot()
    while True:
        bot.run()
        time.sleep(60)  # 1ë¶„ = 60ì´ˆ
