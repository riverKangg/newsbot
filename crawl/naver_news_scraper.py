# naver_news_scraper.py

import requests
from bs4 import BeautifulSoup
import pandas as pd
import os
import sys

def read_excel_file(date, prefix):
    filename = f"{prefix}_{date}.xlsx"
    file_path = os.path.join("../data", filename)

    if os.path.exists(file_path):
        df = pd.read_excel(file_path, engine='openpyxl')
        df = df.dropna(subset=['ë„¤ì´ë²„ë§í¬'])
        df = df.drop_duplicates(subset='ë„¤ì´ë²„ë§í¬').reset_index(drop=True)
        return df
    else:
        print(f"íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•Šì•„ìš”: {file_path}")
        return None

def save_excel_file(df, date, prefix):
    filename = f"{prefix}_{date}_naver.xlsx"
    file_path = os.path.join("../data", filename)
    df.to_excel(file_path, index=False)
    print(f"ë‰´ìŠ¤ ë°ì´í„°ê°€ {filename} íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

def fetch_article_content(url, headers):
    response = requests.get(url, headers=headers, timeout=5)
    soup = BeautifulSoup(response.text, 'html.parser')

    if 'sports' in url:
        content = soup.find('div', class_='_article_content')
    else:
        content = soup.find('div', id='newsct_article')

    content_text = content.get_text(strip=True) if content else ''
    return content_text, soup

def extract_journalist_info(soup):
    jour = soup.find('div', class_='media_end_head_journalist')
    if jour:
        jour_link_tag = jour.find('a')
        jour_name_tag = jour.find('em', class_='media_end_head_journalist_name')

        jour_link = jour_link_tag.get('href') if jour_link_tag else None
        jour_name = jour_name_tag.get_text(strip=True) if jour_name_tag else None
    else:
        jour_link = jour_name = None

    return jour_link, jour_name


def process_links(links, headers):
    contents, jour_links, jour_names = [], [], []

    for url in links:
        if isinstance(url, str) and url.startswith('http'):
            content_text, soup = fetch_article_content(url, headers)
            contents.append(content_text)

            jour_link, jour_name = extract_journalist_info(soup)
            jour_links.append(jour_link)
            jour_names.append(jour_name)
        else:
            contents.append('')
            jour_links.append('')
            jour_names.append('')

    return contents, jour_links, jour_names

def main():
    print("\nğŸ“„ ì‚¬ìš©ë²•: python naver_news_scraper.py [health|cnews] [ë‚ ì§œ: YYYYMMDD]")

    if len(sys.argv) != 3:
        print("\nâ— ì¸ì ì˜¤ë¥˜: íŒŒì¼ ì ‘ë‘ì‚¬ì™€ ë‚ ì§œë¥¼ ì •í™•íˆ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
        sys.exit(1)

    file_prefix = sys.argv[1]
    date_str = sys.argv[2]

    df = read_excel_file(date_str, file_prefix)

    if df is not None:
        print(f"ë°ì´í„°í”„ë ˆì„ì˜ í¬ê¸°: {df.shape}")

        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
        }

        links = list(df['ë„¤ì´ë²„ë§í¬'])
        contents, jour_links, jour_names = process_links(links, headers)

        df['ë³¸ë¬¸'] = contents
        df['ê¸°ìëª…'] = jour_names
        df['ê¸°ìë§í¬'] = jour_links
        save_excel_file(df, date_str, file_prefix)
    else:
        print("ë°ì´í„°í”„ë ˆì„ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ì–´ì„œ í”„ë¡œì„¸ìŠ¤ë¥¼ ì¤‘ì§€í•©ë‹ˆë‹¤.")

if __name__ == "__main__":
    main()
