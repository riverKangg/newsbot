import os
import sys
import time
from datetime import datetime
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from webdriver_manager.chrome import ChromeDriverManager
from bs4 import BeautifulSoup
from urllib.parse import quote

from summary.summarizer import NewsSummarizer
from crawl.naver_news_one import process_link
from api.slack_sender import send_slack_message, format_news_to_message

def web_driver():
    options = Options()
    options.add_argument('--headless')
    options.add_argument('--no-sandbox')
    options.add_argument('--disable-dev-shm-usage')
    options.add_argument('--disable-gpu')
    options.add_argument('--window-size=1920,1080')
    options.add_argument('--remote-debugging-port=9222')

    service = Service(ChromeDriverManager().install())
    driver = webdriver.Chrome(service=service, options=options)
    return driver

def build_naver_news_url(query, date):
    encoded_query = quote(query)
    option_date = f"ds={str(int(date[:4]))}.{date[4:6]}.{date[-2:]}&de={date[:4]}.{date[4:6]}.{date[-2:]}"
    url = f"https://search.naver.com/search.naver?where=news&query={encoded_query}&sm=tab_opt&sort=1&photo=0&field=0&pd=3&{option_date}"
    return url

def naver_news_scraper(query, date, category):
    print(f"ğŸ” ê²€ìƒ‰ ì‹œì‘ - ì¹´í…Œê³ ë¦¬: '{category}', í‚¤ì›Œë“œ: '{query}'")
    url = build_naver_news_url(query, date)
    driver = web_driver()
    news_list = []
    try:
        driver.get(url)
        time.sleep(1)
        soup = BeautifulSoup(driver.page_source, "html.parser")
        news_items = soup.select(".news_area")
        print(f"ğŸ“° ë°œê²¬ëœ ë‰´ìŠ¤ ìˆ˜: {len(news_items)}")
        for item in news_items:
            title_elem = item.select_one(".news_tit")
            title = title_elem.text.strip()
            link = title_elem["href"]
            press_elem = item.select_one(".info.press")
            press = press_elem.text.strip() if press_elem else "ì–¸ë¡ ì‚¬ ì •ë³´ ì—†ìŒ"
            desc_elem = item.select_one(".dsc_txt_wrap")
            description = desc_elem.text.strip() if desc_elem else "ìš”ì•½ ì •ë³´ ì—†ìŒ"

            test = item.find("div", class_="info_group")
            time_elem = test.find('span', class_='info').text.strip()
            naver_link = test.find_all('a')[-1].get('href') if test and 'naver' in test.find_all('a')[-1].get('href') else None

            # ì‹œê°„ íŒŒì‹± ë° í•„í„°ë§
            time_delta_minutes = None
            if 'ë¶„ ì „' in time_elem:
                time_delta_minutes = int(time_elem.replace('ë¶„ ì „', '').strip())
            elif 'ì‹œê°„ ì „' in time_elem:
                time_delta_minutes = int(time_elem.replace('ì‹œê°„ ì „', '').strip()) * 60

            sentiment_label = ""
            if naver_link is not None:
                print(f"ğŸ”— ê¸°ì‚¬ ë§í¬ ë¶„ì„ ì¤‘: {naver_link}")
                content, jour_link, jour_name = process_link(naver_link)
                summarizer = NewsSummarizer()
                prompt = "Return the sentiment of the article as a single word: positive, negative or neutral."
                sentiment_label = summarizer.summarize_with_gpt(content, prompt)
                print(f"ğŸ“ ê°ì • ë¶„ì„ ê²°ê³¼: {sentiment_label}")

            if sentiment_label == "Negative" and time_delta_minutes is not None and time_delta_minutes <= 333:
                news_list.append({
                    "category": category,
                    "keyword": query,
                    "title": title,
                    "press": press,
                    "description" : description,
                    "url": link,
                    "naver_link": naver_link,
                    "time": time_elem,
                    "content": content,
                    "jour_name": jour_name,
                    "sentiment_label": sentiment_label
                })
    finally:
        driver.quit()

    return news_list

if __name__ == "__main__":
    date = datetime.now().strftime('%Y%m%d')
    selected_keywords = {
        "test": ["ìœ¤ì„ì—´"],
        #"ë‹¹ì‚¬": ["ì‚¼ì„±ìƒëª…", "í™ì›í•™"],
        #"ë³´í—˜": ["ìƒëª…ë³´í—˜", "ì†í•´ë³´í—˜", "ìƒë³´", "ì†ë³´", "ë³´í—˜ì‚¬ê¸°",
        #        "ì‹¤ì†", "ë¬´í•´ì§€", "ì €í•´ì§€", "IFRS17", "í‚¥ìŠ¤",
        #        "ì‚¼ì„±í™”ì¬", "í•œí™”ìƒëª…", "êµë³´ìƒëª…", "ì‹ í•œë¼ì´í”„"],
        #"ê·¸ë£¹": ["ì´ì¬ìš©", "í™ë¼í¬", "ì´ë¶€ì§„", "ì´ì„œí˜„", "ì‚¼ì„±ì „ì", "ì‚¼ì„±ë¬¼ì‚°"],
        #"ê¸ˆìœµ": ["ê¸ˆìœµìœ„", "ê¸ˆê°ì›", "ê¹€ë³‘í™˜", "ì´ë³µí˜„", "ê¸ˆìœµì§€ì£¼"]
    }

    all_news_list = []

    while True:
        for category, keyword_list in selected_keywords.items():
            all_news_list = []  # ì¹´í…Œê³ ë¦¬ë³„ ë‰´ìŠ¤ ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”
            for query in keyword_list:
                news = naver_news_scraper(query, date, category)
                all_news_list.extend(news)
                print(all_news_list)

            if all_news_list:  # ì¹´í…Œê³ ë¦¬ë³„ë¡œ ìŠ¬ë™ ì „ì†¡
                message = format_news_to_message(all_news_list)
                print(f"ğŸ“¤ ìŠ¬ë™ìœ¼ë¡œ ì „ì†¡ ì¤‘ - ì¹´í…Œê³ ë¦¬: '{category}', ë‰´ìŠ¤: {len(all_news_list)}ê°œ")
                send_slack_message("#newsbot-test", message)
                print(f"âœ… ìŠ¬ë™ ì „ì†¡ ì™„ë£Œ - ì¹´í…Œê³ ë¦¬: '{category}'")

        print("[ëŒ€ê¸° ì¤‘ ğŸ’¤] 1ë¶„ í›„ ì¬ì‹œì‘\n")
        time.sleep(60)
