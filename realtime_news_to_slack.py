import os
import re
import sys
import json
import time
import random
from datetime import datetime
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from webdriver_manager.chrome import ChromeDriverManager
from bs4 import BeautifulSoup
from urllib.parse import quote

from summary.summarizer import NewsSummarizer
from crawl.naver_news_one import process_link
from api.slack_sender import send_slack_message, format_news_to_message

with open(f"./prompt/cnews_summary.txt", 'r',encoding='utf-8') as file:
    prompt = file.read()
news_sources = [
    # ì¢…í•©ì§€
    "ì¡°ì„ ì¼ë³´", "ì¤‘ì•™ì¼ë³´", "ë™ì•„ì¼ë³´", "í•œêµ­ì¼ë³´", "êµ­ë¯¼ì¼ë³´", "ì„œìš¸ì‹ ë¬¸", "ì„¸ê³„ì¼ë³´",
    "í•œê²¨ë ˆ", "ê²½í–¥ì‹ ë¬¸", "ë¬¸í™”ì¼ë³´", "í—¤ëŸ´ë“œê²½ì œ", "ì•„ì‹œì•„ê²½ì œ", "ë‚´ì¼ì‹ ë¬¸",
    "ë§¤ì¼ê²½ì œ", "í•œêµ­ê²½ì œ", "ì„œìš¸ê²½ì œ", "ë¨¸ë‹ˆíˆ¬ë°ì´", "íŒŒì´ë‚¸ì…œë‰´ìŠ¤", "ì´ë°ì¼ë¦¬",
    "ì•„ì£¼ê²½ì œ", "ë©”íŠ¸ë¡œê²½ì œ",

    # ë°©ì†¡ì‚¬
    "KBS", "MBC", "SBS", "JTBC", "TVì¡°ì„ ", "ì±„ë„A", "MBN", "ì—°í•©ë‰´ìŠ¤TV", "YTN",
    "SBS Biz", "í•œê²½TV", "ë§¤ì¼ê²½ì œTV", "MTN", "CBS",

    # í†µì‹ ì‚¬ ë° ì „ë¬¸ì§€
    "ì—°í•©ë‰´ìŠ¤", "ì—°í•©ì¸í¬ë§¥ìŠ¤", "ë‰´ì‹œìŠ¤", "ë‰´ìŠ¤1", "ë”ë²¨", "ì´íˆ¬ë°ì´", "ë‰´ìŠ¤í† ë§ˆí† ",
    "ì—ë„ˆì§€ê²½ì œ", "ë¸Œë¦¿ì§€ê²½ì œ", "ë§¤ì¼ì¼ë³´", "ì•„ì‹œì•„íƒ€ì„ì¦ˆ", "ì „ìì‹ ë¬¸", "ì¡°ì„ ë¹„ì¦ˆ",
    "ë¨¸ë‹ˆS", "ë””ì§€í„¸íƒ€ì„ìŠ¤", "ì†Œë¹„ìê°€ ë§Œë“œëŠ” ì‹ ë¬¸", "ì²­ë…„ì¼ë³´", "CEOìŠ¤ì½”ì–´ë°ì¼ë¦¬",
    "EBN", "FETV", "êµ¿ëª¨ë‹ê²½ì œ", "ê¸€ë¡œë²Œì´ì½”ë…¸ë¯¹", "ë‰´ë°ì¼ë¦¬", "ë‰´ìŠ¤ì›¨ì´", "ë‰´ìŠ¤í•Œ",
    "ë°ì¼ë¦¬ì•ˆ", "ëŒ€í•œê²½ì œ", "ë¹„ì¦ˆë‹ˆìŠ¤í¬ìŠ¤íŠ¸", "ì•„ì‹œì•„íˆ¬ë°ì´", "ì¿ í‚¤ë‰´ìŠ¤", "ë§¤ê²½ë‹·ì»´",
    "í•œê²½ë‹·ì»´",

    # ë³´í—˜ ë° ê¸ˆìœµ ì „ë¬¸ì§€
    "í•œêµ­ë³´í—˜ì‹ ë¬¸", "ë³´í—˜ì‹ ë³´", "ë³´í—˜ë§¤ì¼", "ë³´í—˜ì €ë„", "ë¹„ì¦ˆì›Œì¹˜", "íŒŒì´ë‚¸ì…œíˆ¬ë°ì´",
    "ì„œìš¸íŒŒì´ë‚¸ìŠ¤", "ëŒ€í•œê¸ˆìœµì‹ ë¬¸", "í•œêµ­ê¸ˆìœµ", "ê¸ˆìœµê²½ì œ"
]

def generate_random_phone_number():
    middle = random.randint(1000, 9999)
    last = random.randint(1000, 9999)
    return f"010-{middle}-{last}"

def parse_response(response):
    try:
        # ì—¬ëŸ¬ ë²ˆ ë‚˜ëˆ„ì–´ì§„ ì‘ë‹µì„ í•˜ë‚˜ë¡œ í•©ì¹˜ê¸°
        if isinstance(response, list):
            response = "".join(response)
        
        # ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì œê±°
        response = response.strip()
        if '```json' in response:
            response = response.split('```json')[1]
        if '```' in response:
            response = response.split('```')[0]
        response = response.strip()
        
        # JSON ë¬¸ìì—´ ì •ê·œí™”
        response = response.replace('\n', ' ').replace('\r', '')
        response = re.sub(r'\s+', ' ', response)
        response = response.replace('False','false').replace('True','true')
        response = re.sub("'", '', response)

        # ì¤‘ë³µëœ JSON ì‘ë‹µ ì œê±°
        if response.count('{') > 1:
            # ë§ˆì§€ë§‰ ì™„ì „í•œ JSON ê°ì²´ë§Œ ì‚¬ìš©
            last_brace = response.rfind('}')
            if last_brace != -1:
                response = response[:last_brace+1]
        
        # JSON íŒŒì‹±
        result = json.loads(response)
        print(result)
        
        # í•„ìˆ˜ í•„ë“œê°€ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ê°’ ì„¤ì •
        if 'is_related' not in result:
            result['is_related'] = False
        if 'label' not in result:
            result['label'] = 'False'
        if 'summary' not in result:
            result['summary'] = 'ìš”ì•½ ì‹¤íŒ¨'
            
        # label ê°’ì´ ì˜ˆìƒëœ í˜•ì‹ì´ ì•„ë‹Œ ê²½ìš° ìˆ˜ì •
        if isinstance(result['label'], bool):
            result['label'] = 'True' if result['label'] else 'False'
        elif result['label'] not in ['True', 'False', 'Positive', 'Negative', 'Neutral']:
            result['label'] = 'False'
            
        return result
    except Exception as e:
        print(f"Unexpected error in parse_response: {e}")
        print(f"Raw response: {response}")
        return {
            'is_related': False,
            'label': 'Neutral',
            'summary': 'ìš”ì•½ ì‹¤íŒ¨'
        }

def process_content_with_prompt(content, prompt):
    try:
        summarizer = NewsSummarizer()
        sentdict_raw = summarizer.summarize_with_gpt(content, prompt)
        sentdict = parse_response(sentdict_raw)

        if sentdict is None:
            raise ValueError("Parsed dictionary is None.")

        is_related = sentdict.get('is_related', False)
        label = sentdict.get('label')
        summary = sentdict.get('summary')

        return is_related, label, summary
    except Exception as e:
        print(f"Error in process_content_with_prompt: {str(e)}")
        print(f"Content: {content[:100]}...")  # ì²« 100ìë§Œ ë¡œê¹…
        return False, "False", "ìš”ì•½ ì‹¤íŒ¨"

def web_driver():
    options = Options()
    options.add_argument('--headless')
    options.add_argument('--no-sandbox')
    options.add_argument('--disable-dev-shm-usage')
    options.add_argument('--disable-gpu')
    options.add_argument('--window-size=1920,1080')
    options.add_argument('--remote-debugging-port=9222')

    service = Service(ChromeDriverManager().install())
    driver = webdriver.Chrome(service=service, options=options)
    return driver

def build_naver_news_url(query, date):
    encoded_query = quote(query)
    option_date = f"ds={str(int(date[:4]))}.{date[4:6]}.{date[-2:]}&de={date[:4]}.{date[4:6]}.{date[-2:]}"
    url = f"https://search.naver.com/search.naver?where=news&query={encoded_query}&sm=tab_opt&sort=1&photo=0&field=0&pd=3&{option_date}"
    return url

def naver_news_scraper(query, date, category):
    print(f"ğŸ” ê²€ìƒ‰ ì‹œì‘ - ì¹´í…Œê³ ë¦¬: '{category}', í‚¤ì›Œë“œ: '{query}'")
    url = build_naver_news_url(query, date)
    driver = web_driver()
    results = [] 
    try:
        driver.get(url)
        time.sleep(1)
        soup = BeautifulSoup(driver.page_source, "html.parser")
        news_items = soup.select(".news_area")
        print(f"ğŸ“° ë°œê²¬ëœ ë‰´ìŠ¤ ìˆ˜: {len(news_items)}")
        for item in news_items:
            title_elem = item.select_one(".news_tit")
            title = title_elem.text.strip()
            link = title_elem["href"]
            press_elem = item.select_one(".info.press")
            press = press_elem.text.strip() if press_elem else "ì–¸ë¡ ì‚¬ ì •ë³´ ì—†ìŒ"
            desc_elem = item.select_one(".dsc_txt_wrap")
            description = desc_elem.text.strip() if desc_elem else "ìš”ì•½ ì •ë³´ ì—†ìŒ"

            test = item.find("div", class_="info_group")
            time_elem = test.find('span', class_='info').text.strip()
            naver_link = test.find_all('a')[-1].get('href') if test and 'naver' in test.find_all('a')[-1].get('href') else None
            if naver_link is not None:
                print(f"ğŸ”— ê¸°ì‚¬ ë§í¬ ë¶„ì„ ì¤‘: {naver_link}")

                # ì‹œê°„ íŒŒì‹± ë° í•„í„°ë§
                time_delta_minutes = None
                if 'ë¶„ ì „' in time_elem:
                    time_delta_minutes = int(time_elem.replace('ë¶„ ì „', '').strip())
                elif 'ì‹œê°„ ì „' in time_elem:
                    time_delta_minutes = int(time_elem.replace('ì‹œê°„ ì „', '').strip()) * 60

                content, jour_link, jour_name = process_link(naver_link)
                summarizer = NewsSummarizer()
                is_related, label, summary = process_content_with_prompt(content, prompt)
 
                print(f"ğŸ“Š ë¶„ì„ ê²°ê³¼:")
                print(f"  - ê´€ë ¨ì„±: {is_related}")
                print(f"  - ê°ì •: {label}")
                print(f"  - ìš”ì•½: {summary}")
                print(f"  - ê¸°ì: {jour_name}")
                print(f"  - ê¸°ì ë§í¬: {jour_link}")
 
                if label == "Negative" and time_delta_minutes is not None and time_delta_minutes <= 2:
                    random_phone_number = generate_random_phone_number() if press in news_sources else None

                    news_item = {
                        "category": category,
                        "keyword": query,
                        "title": title,
                        "press": press,
                        "description": description,
                        "url": link,
                        "naver_link": naver_link,
                        "time": time_elem,
                        "content": content,
                        "jour_name": jour_name,
                        "sentiment_label": sentiment_label,
                        "phone_number" : random_phone_number,
                        "neg_sent" : neg_sent
                    }
                    message = format_news_to_message(news_item)
                    send_slack_message("#news-feed", message)
                    print(f"ğŸ“¤ ìŠ¬ë™ìœ¼ë¡œ ì „ì†¡ ì™„ë£Œ - ì œëª©: '{title}'")
                    results.append(news_item)
    finally:
        driver.quit()
    return results

if __name__ == "__main__":
    date = datetime.now().strftime('%Y%m%d')
    selected_keywords = {
        "test": ["ìœ¤ì„ì—´"],
        "ë‹¹ì‚¬": ["ì‚¼ì„±ìƒëª…", "í™ì›í•™"],
        "ë³´í—˜": ["ìƒëª…ë³´í—˜", "ì†í•´ë³´í—˜", "ìƒë³´", "ì†ë³´", "ë³´í—˜ì‚¬ê¸°",
                "ì‹¤ì†", "ë¬´í•´ì§€", "ì €í•´ì§€", "IFRS17", "í‚¥ìŠ¤",
                "ì‚¼ì„±í™”ì¬", "í•œí™”ìƒëª…", "êµë³´ìƒëª…", "ì‹ í•œë¼ì´í”„"],
        "ê·¸ë£¹": ["ì´ì¬ìš©", "í™ë¼í¬", "ì´ë¶€ì§„", "ì´ì„œí˜„", "ì‚¼ì„±ì „ì", "ì‚¼ì„±ë¬¼ì‚°"],
        "ê¸ˆìœµ": ["ê¸ˆìœµìœ„", "ê¸ˆê°ì›", "ê¹€ë³‘í™˜", "ì´ë³µí˜„", "ê¸ˆìœµì§€ì£¼"]
    }

    while True:
        for category, keyword_list in selected_keywords.items():
            for query in keyword_list:
                naver_news_scraper(query, date, category)

        print("[ëŒ€ê¸° ì¤‘ ğŸ’¤] 1ë¶„ í›„ ì¬ì‹œì‘\n")
        time.sleep(60)
