import os
import sys
import time
import asyncio
import pandas as pd
import numpy as np
from datetime import datetime
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.cluster import DBSCAN
from tqdm import tqdm
from dotenv import load_dotenv
from openai import AsyncOpenAI

client = None  # ê¸€ë¡œë²Œ AsyncOpenAI í´ë¼ì´ì–¸íŠ¸

def load_api_key():
    global client
    load_dotenv('../.env')
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        raise ValueError("âŒ OPENAI_API_KEYê°€ .envì—ì„œ ë¡œë“œë˜ì§€ ì•Šì•˜ì–´ìš”!")
    client = AsyncOpenAI(api_key=api_key)

def load_data(file_path, max_chars=800):
    df = pd.read_excel(file_path)
    df = df.dropna(subset=["label"]).reset_index(drop=True)
    #df["text"] = df["ì œëª©"].fillna("") + " " + df["ë³¸ë¬¸"].apply(lambda x: x[:max_chars]).fillna("")
    def get_text(row):
        if row["label"] in [True, "Negative"]:
            title = row["ì œëª©"] if pd.notna(row["ì œëª©"]) else ""
            content = row["ë³¸ë¬¸"][:max_chars] if pd.notna(row["ë³¸ë¬¸"]) else ""
            return title + " " + content
        return None

    df["text"] = df.apply(get_text, axis=1)
    return df

async def async_get_embedding(text, model="text-embedding-3-small", retry=3):
    if text is None:
        return [0.0] * 1536  # ë§Œì•½ textê°€ Noneì´ë¼ë©´ ì‹¤íŒ¨ ì‹œ zero vector ë°˜í™˜

    text = text.replace("\n", " ")
    for _ in range(retry):
        try:
            response = await client.embeddings.create(
                input=[text],
                model=model
            )
            return response.data[0].embedding
        except Exception as e:
            print(f"âš ï¸ Embedding error: {e}")
            await asyncio.sleep(2)
    return [0.0] * 1536  # ì‹¤íŒ¨ ì‹œ zero vector

async def embed_all_async(df, batch_size=100):
    print("â–¶ ì„ë² ë”© ìƒì„± ì¤‘ (ë¹„ë™ê¸°)...")
    texts = df["text"].tolist()
    embeddings = []

    for i in tqdm(range(0, len(texts), batch_size)):
        batch = texts[i:i+batch_size]
        tasks = [async_get_embedding(text) for text in batch]
        results = await asyncio.gather(*tasks)
        embeddings.extend(results)

    df["embedding"] = embeddings
    return df

def cluster_articles(df, eps=0.3, min_samples=2):
    print("â–¶ ìœ ì‚¬ë„ ê³„ì‚° ë° í´ëŸ¬ìŠ¤í„°ë§ ì¤‘...")
    X = np.array(df["embedding"].tolist())
    sim_matrix = cosine_similarity(X)

    # ê±°ë¦¬ í–‰ë ¬ë¡œ ë³€í™˜ (ìŒìˆ˜ ë°©ì§€)
    distance_matrix = 1 - sim_matrix
    distance_matrix = np.clip(distance_matrix, 0, 1)

    clustering = DBSCAN(eps=eps, min_samples=min_samples, metric="precomputed")
    labels = clustering.fit_predict(distance_matrix)
    df["cluster"] = labels
    return df

def select_representative(group):
    priority = ["ì¡°ì„ ì¼ë³´", "ì¤‘ì•™ì¼ë³´", "ë™ì•„ì¼ë³´", "ì„œìš¸ê²½ì œ", "í•œêµ­ê²½ì œ", "ë§¤ì¼ê²½ì œ"]
    
    # 1. ì œëª©ì— "ë‹¨ë…" í¬í•¨ëœ ê¸°ì‚¬ ìˆìœ¼ë©´ ê·¸ ì¤‘ ì²« ë²ˆì§¸
    exclusive = group[group["ì œëª©"].str.contains("ë‹¨ë…", na=False)]
    if not exclusive.empty:
        return exclusive.iloc[0]

    # 2. ìš°ì„ ìˆœìœ„ ì–¸ë¡ ì‚¬ í•„í„°
    for media in priority:
        selected = group[group["ì–¸ë¡ ì‚¬"] == media]
        if not selected.empty:
            return selected.iloc[0]

    # 3. ê·¸ë˜ë„ ì—†ìœ¼ë©´ ê·¸ëƒ¥ ì²« ë²ˆì§¸
    return group.iloc[0]

def force_cluster_for_exclusives(df):
    exclusive_mask = df["ì œëª©"].str.contains("ë‹¨ë…", na=False)
    noise_mask = df["cluster"] == -1
    exclusive_noise_idx = df[exclusive_mask & noise_mask].index

    # ìƒˆë¡œìš´ cluster ë²ˆí˜¸ë¥¼ ê°€ì¥ í° í´ëŸ¬ìŠ¤í„° ë²ˆí˜¸ ë‹¤ìŒë¶€í„° ë¶€ì—¬
    max_cluster = df["cluster"].max()
    for i, idx in enumerate(exclusive_noise_idx):
        df.at[idx, "cluster"] = max_cluster + 1 + i

    return df


def extract_representatives(df):
    print("â–¶ ëŒ€í‘œ ê¸°ì‚¬ ì„ íƒ ì¤‘...")
    representatives = []
    for label in set(df["cluster"]):
        group = df[df["cluster"] == label]
        if label == -1:
            representatives.append(group)  # noiseëŠ” ì „ë¶€ í¬í•¨
        else:
            rep = select_representative(group)
            representatives.append(pd.DataFrame([rep]))
    return pd.concat(representatives, ignore_index=True)

def save_results(df, output_path="ëŒ€í‘œê¸°ì‚¬_ê²°ê³¼_openai.xlsx"):
    df.to_excel(output_path, index=False)
    print(f"âœ… ì™„ë£Œ! ê²°ê³¼ ì €ì¥ë¨: {output_path}")

def main():
    print("\nğŸ“„ ì‚¬ìš©ë²•: python run_cluster.py [health|cnews] [ë‚ ì§œ: YYYYMMDD]")

    if len(sys.argv) != 3:
        print("\nâ— ì¸ì ì˜¤ë¥˜: íŒŒì¼ ì ‘ë‘ì‚¬ì™€ ë‚ ì§œë¥¼ >ì •í™•íˆ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
        return

    file_prefix = sys.argv[1]
    date_str = sys.argv[2]

    print(f"\nğŸ” ì²˜ë¦¬ ì¤‘ì¸ íŒŒì¼ ì •ë³´:")
    print(f" - ì¹´í…Œê³ ë¦¬ : {file_prefix}")
    print(f" - ë‚ ì§œ     : {date_str}")

    data_directory = "../data/"

    input_path = f"{data_directory}{file_prefix}_{date_str}_summary.xlsx"
    output_path = f"{data_directory}{file_prefix}_{date_str}_cluster.xlsx"

    load_api_key()
    df = load_data(input_path)
    df = asyncio.run(embed_all_async(df))  # async ì²˜ë¦¬!
    df = cluster_articles(df)
    df = force_cluster_for_exclusives(df)
    result_df = extract_representatives(df)
    save_results(result_df, output_path)

if __name__ == "__main__":
    main()

